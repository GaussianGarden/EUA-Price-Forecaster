{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Aggregation of Small Neural Networks\n",
    "Before utilizing the Twitter data, we will build small neural networks and combining them to an ensemble by bagging, i.e. bootstrap aggregation. For the exploratory data analysis, see the corresponding Jupyter Notebook.\n",
    "\n",
    "### Loading and Preparing the Data\n",
    "We start by loading the data and doing some light feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import preprocessing.numerical_data as pnd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"data\", \"raw\", \"input.csv\"), sep=\";\", index_col=0, parse_dates=[0], dtype=np.float64)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first apply the transformations that were development during the above mentioned EDA part. In summary, these comprised removing NA values, preventing data leaks by shifting some column values (e.g. shifting the \"Settle\" columns a day back). Having seen that the price columns seem to follow a log-normal distribution, we transform these by applying the natural logarithm. Please note that I will omit a formal hypothesis test for log-normality, so consider this transformation a heuristic. To avoid issues with logarithms near or at 0, we add 1 to the columns in question. The function $\\left[0, \\infty\\right) \\ni x \\mapsto \\log(1+x)$ maps to $\\left[0, \\infty\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pnd.chain_preparations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggable_columns= [col for col in df.columns if any(word in col for word in (\"Open\", \"High\", \"Low\", \"Settle\"))\n",
    "                   and not \"Interest\" in col]\n",
    "df[loggable_columns] = (df[loggable_columns] + 1).apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnd.plot_univariate_distributions(df, loggable_columns, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the prior assumption of log-normality was justified at least for Gas and Oil columns. Since no obvious seasonality could be seen during the EDA, we will omit season based feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting and Scaling the Data\n",
    "In preparation for the training process, we split the data by a 4:1 ratio. Additionally, we transform the data by using a standard scaler, that is, we center the data around mean 0 and scale to achieve variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "cols = ['Open', 'Prev. Day Open Interest', 'Gas.Open',\n",
    "       'Coal.Open', 'Oil.Open', 'Prev. Day High',\n",
    "       'Prev. Day Low', 'Prev. Day Settle', 'Prev. Day Change',\n",
    "       'Prev. Day Gas.High', 'Prev. Day Gas.Low', 'Prev. Day Gas.Settle',\n",
    "       'Prev. Day Gas.Change', 'Prev. Day Coal.High', 'Prev. Day Coal.Low',\n",
    "       'Prev. Day Coal.Settle', 'Prev. Day Coal.Change', 'Prev. Day Oil.High',\n",
    "       'Prev. Day Oil.Low', 'Prev. Day Oil.Settle', 'Prev. Day Oil.Change']\n",
    "\n",
    "X = df[cols].values\n",
    "y = df[\"Settle\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "For the model, we use a relatively small Neural Network consisting of two hidden layers. The number of hidden units will be 16 and 8, respectively. To speed up learning, we apply batch normalization after the first hidden layer. Both hidden activations will be rectified linear units (ReLUs). We will optimize with the Adam optimizer and minimize the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "import models.text_free as mtf\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fit the model to the training data. We will use a small ensemble with only 15 regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BaggingRegressor(KerasRegressor(mtf.simple_nn, input_dim=X.shape[1], epochs=500, batch_size=128, verbose=0),\n",
    "                             n_estimators=15, n_jobs=-1, iid=False)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assess the model performance according to the mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training MSE:\", mean_squared_error(estimator.predict(X_train), y_train))\n",
    "print(\"Test MSE:\", mean_squared_error(estimator.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that test performance is worse than training performance. This is likely happening due to overfitting. The model above has a total of 529 trainable parameters which is more than half of the training samples. Since it is next to impossible to generate more training data at this point, we have to change the model instead of the data. There are two relatively obvious ways to overcome this issue, one being the reduction of model complexity (e.g. less hidden units) and the other one being more regularization (e.g. $L^2$-regularization or dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.estimators_[0].model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, we should make an attempt to reduce the variance of the model. For now, we will stick with dropout with some probability $p \\in [0, 1]$ which randomly blocks units from the forward propagation pass. The decision random variables are iid $\\sim{}{\\rm Bernoulli}(p)$. We will use a line search to find a suitable value for the dropout probability $p$. The cross validation error will, however, still underestimate the true error. This is because we have a subtle data leak in our fitting process. The standard scaler was trained with the whole training set. Thus, the individual models in the cross-validation steps contain information about their respective validation data. To avoid this, one could include the scaling step into the model fitting process. That way, no data is leaked.\n",
    "\n",
    "Due to an issue with Keras, we will have to manually write the GridSearch at the moment of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "param_grid = {\"n_estimators\": [15], \"base_estimator__dropout_proba\": [0.0, 0.1, 0.2, 0.3, 0.4]}\n",
    "\n",
    "best_model_cv = GridSearchCV(BaggingRegressor(KerasRegressor(mtf.simple_nn, input_dim=X.shape[1], epochs=500, batch_size=128,\n",
    "                                                             verbose=0), n_jobs=-1), param_grid, cv=5, n_jobs=-1, iid=False) \n",
    "best_model_cv.fit(X_train, y_train)\n",
    "best_model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify that regularization did indeed increase the performance. For this, we will investigate the parameters chosen by the grid search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
